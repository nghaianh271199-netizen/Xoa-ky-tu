import streamlit as st
import re
import json
from docx import Document

st.set_page_config(page_title="VÄƒn báº£n chuáº©n hÃ³a (OCR fix)", layout="wide")

# --- helper: extract full text from docx (paragraphs + tables + headers/footers)
def extract_text_from_docx(file_stream):
    doc = Document(file_stream)
    parts = []

    def para_text(p):
        # join runs to keep raw characters
        return "".join([r.text for r in p.runs]).strip()

    for p in doc.paragraphs:
        t = para_text(p)
        if t:
            parts.append(t)

    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                for p in cell.paragraphs:
                    t = para_text(p)
                    if t:
                        parts.append(t)

    for section in doc.sections:
        try:
            for p in section.header.paragraphs:
                t = para_text(p)
                if t:
                    parts.append(t)
            for p in section.footer.paragraphs:
                t = para_text(p)
                if t:
                    parts.append(t)
        except Exception:
            pass

    return "\n".join(parts)


# --- Detect if a string contains Vietnamese vowel characters (unicode-aware) ---
VOWEL_PATTERN = r"[aeiouyÃ Ã¡áº¡áº£Ã£Ã¢áº§áº¥áº­áº©áº«Äƒáº±áº¯áº·áº³áºµÃ¨Ã©áº¹áº»áº½Ãªá»áº¿á»‡á»ƒá»…Ã¬Ã­á»‹á»‰Ä©Ã²Ã³á»á»ÃµÃ´á»“á»‘á»™á»•á»—Æ¡á»á»›á»£á»Ÿá»¡Ã¹Ãºá»¥á»§Å©Æ°á»«á»©á»±á»­á»¯á»³Ã½á»µá»·á»¹Ä‘]"
_vowel_re = re.compile(VOWEL_PATTERN, flags=re.I | re.UNICODE)


# === improved OCR merging:
# Try to greedily merge small tokens into plausible syllables:
def merge_ocr_tokens(text: str) -> str:
    if not text:
        return text

    # tokenise but keep punctuation as separate tokens
    tokens = re.findall(r"\w+|[^\w\s]", text, flags=re.UNICODE)
    out_tokens = []
    i = 0
    n = len(tokens)

    while i < n:
        tok = tokens[i]

        # if punctuation, just append
        if re.fullmatch(r'[^\w\s]', tok, flags=re.UNICODE):
            out_tokens.append(tok)
            i += 1
            continue

        # if token already contains a vowel, treat alone (likely a valid syllable/word)
        if _vowel_re.search(tok):
            out_tokens.append(tok)
            i += 1
            continue

        # otherwise try to merge with next 1 or 2 tokens to create candidate containing vowel
        merged = None
        # try length 3 (tok + tok1 + tok2)
        if i + 2 < n:
            cand = tokens[i] + tokens[i+1] + tokens[i+2]
            if not any(re.fullmatch(r'[^\w\s]', x, flags=re.UNICODE) for x in (tokens[i+1], tokens[i+2])) and _vowel_re.search(cand):
                merged = cand
                i += 3
        # try length 2 (tok + tok1)
        if merged is None and i + 1 < n:
            cand = tokens[i] + tokens[i+1]
            if not re.fullmatch(r'[^\w\s]', tokens[i+1], flags=re.UNICODE) and _vowel_re.search(cand):
                merged = cand
                i += 2

        if merged:
            out_tokens.append(merged)
        else:
            # nothing to merge -> append tok
            out_tokens.append(tok)
            i += 1

    # Reconstruct text: put a space between tokens except before punctuation and after opening punctuation
    res_parts = []
    for idx, t in enumerate(out_tokens):
        res_parts.append(t)
        if idx + 1 < len(out_tokens):
            nxt = out_tokens[idx + 1]
            if not re.fullmatch(r'[^\w\s]', nxt, flags=re.UNICODE):  # next is not punctuation
                res_parts.append(" ")

    return "".join(res_parts)


# === Fix missing spacing when two words are glued: "á»ŸÄ‘Ã³" -> "á»Ÿ Ä‘Ã³"
def fix_missing_spacing(text: str) -> str:
    # add space between vowel-with-diacritic and ascii letter, or ascii letter and vowel-with-diacritic
    vowels = "Ã Ã¡áº¡áº£Ã£Ã¢áº§áº¥áº­áº©áº«Äƒáº±áº¯áº·áº³áºµÃ¨Ã©áº¹áº»áº½Ãªá»áº¿á»‡á»ƒá»…Ã¬Ã­á»‹á»‰Ä©Ã²Ã³á»á»ÃµÃ´á»“á»‘á»™á»•á»—Æ¡á»á»›á»£á»Ÿá»¡Ã¹Ãºá»¥á»§Å©Æ°á»«á»©á»±á»­á»¯á»³Ã½á»µá»·á»¹Ä‘"
    pattern1 = rf'([{vowels}])([A-Za-z])'
    pattern2 = rf'([A-Za-z])([{vowels}])'
    text = re.sub(pattern1, r'\1 \2', text, flags=re.UNICODE)
    text = re.sub(pattern2, r'\1 \2', text, flags=re.UNICODE)
    return text


# === Remove redundant spaces and collapse repeated dots
def fix_basic_spacing(text: str) -> str:
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'\.{2,}', '.', text)
    return text.strip()


# === Full normalize pipeline (applies all fixes) ===
def normalize_text(text: str) -> str:
    if not text:
        return ""

    # 1) remove undesirable characters but keep basic punctuation . , ; : ? ! ( ) and newlines
    text = re.sub(r'[â€œâ€\"\'\*\~\^\%\$\#\@\[\]\{\}\<\>\\\/\=\+]', '', text)

    # 2) normalize hyphen types -> dot (per requirement)
    text = text.replace('-', '.')

    # 3) collapse multiple dots
    text = re.sub(r'\.{2,}', '.', text)

    # 4) lower-case the whole text (spec: bold -> lowercase; we keep overall lowercase to be consistent)
    text = text.lower()

    # 5) basic spacing cleanup
    text = fix_basic_spacing(text)

    # 6) merge OCR-separated letters/syllables
    text = merge_ocr_tokens(text)

    # 7) after merging, fix leftover small spacing artifacts
    text = fix_basic_spacing(text)

    # 8) fix glued words (missing spacing)
    text = fix_missing_spacing(text)

    # 9) final cleanup
    text = fix_basic_spacing(text)

    return text


# === copy button using JS (works in Streamlit) ===
def js_copy_button(text: str, label: str = "ğŸ“‹ Copy toÃ n bá»™"):
    # safe JSON encode the text to embed in JS
    encoded = json.dumps(text)
    html = f"""
        <button id="copy-btn">{label}</button>
        <script>
        const btn = document.getElementById("copy-btn");
        btn.addEventListener("click", async () => {{
            try {{
                await navigator.clipboard.writeText({encoded});
                btn.innerText = "âœ… ÄÃ£ copy";
            }} catch (e) {{
                alert("KhÃ´ng thá»ƒ copy tá»± Ä‘á»™ng â€” vui lÃ²ng bÃ´i Ä‘en vÃ  Ctrl+C");
            }}
        }});
        </script>
    """
    st.markdown(html, unsafe_allow_html=True)


# ------------------ Streamlit UI ------------------
st.title("ğŸ“„ CÃ´ng cá»¥ Chuáº©n hÃ³a VÄƒn báº£n (OCR-fix nÃ¢ng cao)")
st.write(
    "Upload DOCX hoáº·c dÃ¡n vÄƒn báº£n rá»“i báº¥m **âš™ï¸ Xá»­ lÃ½ vÄƒn báº£n**. "
    "Quy táº¯c: loáº¡i bá» ngoáº·c kÃ©p vÃ  kÃ½ tá»± Ä‘áº·c biá»‡t, '-' -> '.', gom nhiá»u '.' thÃ nh 1, "
    "sá»­a lá»—i OCR (kÃ½ tá»±/syllable bá»‹ tÃ¡ch), chÃ¨n khoáº£ng tráº¯ng náº¿u tá»« bá»‹ dÃ­nh."
)

mode = st.radio("PhÆ°Æ¡ng thá»©c nháº­p:", ["ğŸ“‚ Táº£i file DOCX", "âŒ¨ï¸ Nháº­p vÄƒn báº£n"])
input_text = ""

if mode.startswith("ğŸ“‚"):
    uploaded = st.file_uploader("Chá»n file .docx", type=["docx"])
    if uploaded:
        try:
            input_text = extract_text_from_docx(uploaded)
        except Exception as e:
            st.error("Lá»—i khi Ä‘á»c file .docx: " + str(e))

else:
    input_text = st.text_area("DÃ¡n hoáº·c nháº­p vÄƒn báº£n á»Ÿ Ä‘Ã¢y:", height=300)

# xá»­ lÃ½ khi báº¥m nÃºt
if st.button("âš™ï¸ Xá»­ lÃ½ vÄƒn báº£n"):
    if not input_text or not input_text.strip():
        st.warning("Vui lÃ²ng táº£i lÃªn hoáº·c nháº­p vÄƒn báº£n trÆ°á»›c khi xá»­ lÃ½.")
    else:
        st.subheader("ğŸ“Œ VÄƒn báº£n gá»‘c")
        st.text_area("Gá»‘c", value=input_text, height=200)

        processed = normalize_text(input_text)

        st.subheader("âœ… VÄƒn báº£n Ä‘Ã£ chuáº©n hÃ³a")
        st.text_area("Káº¿t quáº£", value=processed, height=300)

        # JS copy button
        js_copy_button(processed)

        st.info("Ghi chÃº: thuáº­t toÃ¡n lÃ  heuristic â€” náº¿u cÃ²n chá»— chÆ°a Ä‘Ãºng, mÃ¬nh cÃ³ thá»ƒ bá»• sung quy táº¯c hoáº·c dÃ¹ng bá»™ tÃ¡ch tá»« tiáº¿ng Viá»‡t (underthesea/pyvi) Ä‘á»ƒ cáº£i thiá»‡n chÃ­nh xÃ¡c hÆ¡n.")
